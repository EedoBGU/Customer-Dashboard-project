{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix customer dashboard data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import time\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data from redshift to dataframe named \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Enter Here the table of the new merchant data instead of playground.lightricks_data\n",
    "\n",
    "QUERY = \"\"\"\n",
    "SELECT *\n",
    "FROM playground.chegg_acquiring \n",
    "\"\"\"\n",
    "\n",
    "def extract_data_from_result(result):\n",
    "    columns = []\n",
    "    rows = []\n",
    "\n",
    "    for column in result[\"ColumnMetadata\"]:\n",
    "        columns.append(column[\"name\"])\n",
    "\n",
    "    for result_row in result[\"Records\"]:\n",
    "        row_values = []\n",
    "        for result_column in result_row:\n",
    "            # Handle None values\n",
    "            row_values.append(list(result_column.values())[0] if result_column else None)\n",
    "        rows.append(row_values)\n",
    "\n",
    "    return columns, rows\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    redshift_client = boto3.client(\"redshift-data\", region_name=\"us-east-1\")\n",
    "    \n",
    "    # Execute the query\n",
    "    response = redshift_client.execute_statement(\n",
    "        Database=\"analytics\",\n",
    "        DbUser='eedobounce',\n",
    "        ClusterIdentifier=\"analytics-redshift\",\n",
    "        Sql=QUERY,\n",
    "        \n",
    "    )\n",
    "    print(f\"Query Response: {response}\")\n",
    "    \n",
    "    query_id = response[\"Id\"]\n",
    "    query_status = \"STARTED\"\n",
    "    \n",
    "    # Check query status in a loop\n",
    "    while query_status in [\"STARTED\", \"SUBMITTED\", \"PICKED\", \"WIP\"]:\n",
    "        time.sleep(5)  # Wait for 5 seconds before checking the status again\n",
    "        query_state = redshift_client.describe_statement(Id=query_id)\n",
    "        query_status = query_state[\"Status\"]\n",
    "        print(f\"Query State: {query_state}\")\n",
    "    \n",
    "    # Check the final status of the query\n",
    "    if query_status == \"FINISHED\":\n",
    "        print(\"Query finished successfully.\")\n",
    "        try:\n",
    "            results = redshift_client.get_statement_result(Id=query_id)\n",
    "        except redshift_client.exceptions.ResourceNotFoundException:\n",
    "            print(\"Resource not found.\")\n",
    "            results = {\"ColumnMetadata\": [], \"Records\": []}\n",
    "        \n",
    "        # Extract data and create DataFrame\n",
    "        columns, rows = extract_data_from_result(result=results)\n",
    "        data = pd.DataFrame(rows, columns=columns)\n",
    "        print(\"DataFrame created successfully.\")\n",
    "        print(data.head())\n",
    "    else:\n",
    "        print(f\"Query did not finish successfully. Final status: {query_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download exchange rate table from Redshift \n",
    "QUERY = \"\"\"\n",
    "SELECT *\n",
    "FROM dms_analyst.exchangerate\n",
    "\"\"\"\n",
    "\n",
    "def extract_data_from_result(result):\n",
    "    columns = []\n",
    "    rows = []\n",
    "\n",
    "    for column in result[\"ColumnMetadata\"]:\n",
    "        columns.append(column[\"name\"])\n",
    "\n",
    "    for result_row in result[\"Records\"]:\n",
    "        row_values = []\n",
    "        for result_column in result_row:\n",
    "            # Handle None values\n",
    "            row_values.append(list(result_column.values())[0] if result_column else None)\n",
    "        rows.append(row_values)\n",
    "\n",
    "    return columns, rows\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    redshift_client = boto3.client(\"redshift-data\", region_name=\"us-east-1\")\n",
    "    \n",
    "    # Execute the query to fetch the exchange rate table\n",
    "    response = redshift_client.execute_statement(\n",
    "        Database=\"analytics\",\n",
    "        DbUser='eedobounce',\n",
    "        ClusterIdentifier=\"analytics-redshift\",\n",
    "        Sql=QUERY,\n",
    "    )\n",
    "    print(f\"Query Response: {response}\")\n",
    "    \n",
    "    query_id = response[\"Id\"]\n",
    "    query_status = \"STARTED\"\n",
    "    \n",
    "    # Check query status in a loop\n",
    "    while query_status in [\"STARTED\", \"SUBMITTED\", \"PICKED\", \"WIP\"]:\n",
    "        time.sleep(5)  # Wait for 5 seconds before checking the status again\n",
    "        query_state = redshift_client.describe_statement(Id=query_id)\n",
    "        query_status = query_state[\"Status\"]\n",
    "        print(f\"Query State: {query_state}\")\n",
    "    \n",
    "    # Check the final status of the query\n",
    "    if query_status == \"FINISHED\":\n",
    "        print(\"Query finished successfully.\")\n",
    "        try:\n",
    "            results = redshift_client.get_statement_result(Id=query_id)\n",
    "        except redshift_client.exceptions.ResourceNotFoundException:\n",
    "            print(\"Resource not found.\")\n",
    "            results = {\"ColumnMetadata\": [], \"Records\": []}\n",
    "        \n",
    "        # Extract data and create DataFrame for the exchange rate table\n",
    "        columns, rows = extract_data_from_result(result=results)\n",
    "        exchange_rate_table = pd.DataFrame(rows, columns=columns)\n",
    "        print(\"Exchange Rate DataFrame created successfully.\")\n",
    "        print(exchange_rate_table.head())\n",
    "    else:\n",
    "        print(f\"Query did not finish successfully. Final status: {query_status}\")\n",
    "\n",
    "\n",
    "exchange_rate_table['date'] = pd.to_datetime(exchange_rate_table['date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, columns_mapping, unique_columns, sort_data):\n",
    "    \n",
    "    # Mapping of columns\n",
    "    \n",
    "    for k, v in columns_mapping.items():\n",
    "        if v in data.columns:\n",
    "            data.rename(columns={v: k}, inplace=True)\n",
    "    \n",
    "    #Remove duplicates based on unique_columns and duplicate_strategy\n",
    "    sorted_by = unique_columns + sort_data\n",
    "    data = data.sort_values(by=sorted_by)\n",
    "    data.drop_duplicates(subset=unique_columns, keep='first', inplace=True)\n",
    "    \n",
    "    # Status mapping Left is the status in the data and right is the status we want to map to\n",
    "    status_mapping = {\n",
    "        'Approved': 'Approved',\n",
    "        'Declined': 'Declined',\n",
    "        'Failed': 'Declined',  \n",
    "        'Paid': 'Approved',\n",
    "        'Success': 'Approved'\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "    \n",
    "    #status mapping    \n",
    "    data['status'] = data['status'].apply(lambda x: status_mapping.get(x, x))\n",
    "\n",
    "    # Declined reason mapping\n",
    "    # Define conditions and corresponding values as a dictionary\n",
    "    regex_values_dict = {\n",
    "        r'.*insufficient.*': 'insufficient funds',   \n",
    "        r'payment.*complete': 'payment complete',\n",
    "        r'do.*not.*honor': 'do not honor',\n",
    "        r'transaction.*not.*allowed': 'transaction not allowed',\n",
    "        r'stripe.*block': 'blocked by Stripe',\n",
    "        r'.*did.*not.*return': 'no further details',  \n",
    "        r'block.*lists': 'block lists rules',\n",
    "        r'.*expired.*card': 'expired card',\n",
    "        r'.*try.*again.*later': 'try again later',\n",
    "        r'.*invalid.*account': 'invalid account',\n",
    "        r'.*invalid.*pin.*': 'invalid pin',\n",
    "        r'.*invalid.*cvc.*': 'invalid cvc',\n",
    "        r'.*invalid.*amount.*': 'invalid amount',\n",
    "        r'incorrect.*number': 'incorrect number',\n",
    "        r'.*incorrect.*cvc.*': 'incorrect cvc',\n",
    "        r'.*blocked.*by.*merchant.*rule': 'blocked by merchant rule',\n",
    "        r'pickup.*card': 'pickup_card',\n",
    "        r'processing.*error': 'processing error',\n",
    "        r'stolen.*card': 'stolen card',\n",
    "        r'lost.*card': 'lost card',\n",
    "        r'.*fraud.*': 'Processor Declined - Fraud Suspected',\n",
    "        r'limit.*exceeded': 'insufficient funds',\n",
    "        r'approved': 'Approved',\n",
    "        r'reenter.*transaction': 'reenter_transaction',\n",
    "        r'Life cycle.*': 'cannot authorize at this time life cycle',\n",
    "        r'82.*Policy': 'expired card',\n",
    "        r'.*Insufficient.*': 'insufficient funds',\n",
    "        r'card_velocity_exceeded': 'card velocity exceeded',\n",
    "        r'withdrawal_count_limit_exceeded': 'withdrawal count limit exceeded',\n",
    "        r'incorrect_number': 'incorrect number',\n",
    "        r'do_not_honor': 'do not honor',\n",
    "        r'call_issuer': 'call issuer',\n",
    "        r'transaction_not_allowed': 'transaction not allowed',\n",
    "        r'revocation_of_authorization': 'revocation of authorization',\n",
    "        r'revocation_of_all_authorization': 'revocation of all authorization',\n",
    "        r'reenter_transaction': 'reenter transaction',\n",
    "        r'service_not_allowed': 'service not allowed',\n",
    "        r'generic_decline': 'generic decline',\n",
    "        r'no_action_taken': 'no action taken',\n",
    "        r'stop_payment_order': 'stop payment order',\n",
    "        r'try_again_later': 'try again later',\n",
    "        r'processing_error': 'processing error',\n",
    "        r'do_not_try_again': 'do not try again',\n",
    "        r'issuer_not_available': 'issuer not available',\n",
    "        r'.*invalid_number.*': 'invalid number',\n",
    "        r'highest_risk_level': 'highest risk level',\n",
    "        r'NULL': 'stripe blocked payment',\n",
    "        r'previously_declined_do_not_retry': 'stripe blocked payment',\n",
    "        r'requested_block_on_incorrect_cvc': 'requested block on incorrect cvc',\n",
    "        r'.*expired_card.*': 'expired card',\n",
    "        r'invalid_expiry_month': 'invalid expiry month',\n",
    "        r'invalid_expiry_year': 'invalid expiry year',\n",
    "        r'.*stolen.*card.*': 'stolen card',\n",
    "        r'.*lost_card.*': 'lost card',\n",
    "        r'.*pickup_card.*': 'pickup card',\n",
    "        r'blocklist': 'blocklist',\n",
    "        r'merchant_blacklist': 'merchant blacklist',\n",
    "        r'rule': 'merchant rule',\n",
    "        r'.*incorrect_pin.*': 'incorrect pin',\n",
    "        r'pin_try_exceeded': 'pin try exceeded',\n",
    "        r'authentication_required': 'authentication required',\n",
    "        r'approve_with_id': 'approve with id',\n",
    "        r'security_violation': 'security violation',\n",
    "        r'elevated_risk_level': 'elevated risk level',\n",
    "        r'restricted_card': 'card restriction',\n",
    "        r'fraudulent': 'stripe fraud',\n",
    "        r'currency_not_supported': 'currency not supported',\n",
    "        r'card_not_supported': 'card not supported',\n",
    "        r'duplicate_transaction': 'duplicate transaction',\n",
    "        r'incorrect_zip': 'incorrect zip',\n",
    "        r'new_account_information_available': 'new account information available',\n",
    "        r'not_permitted': 'not permitted',\n",
    "        r'testmode_decline': 'stripe test decline',\n",
    "        r'offline_pin_required': 'offline pin required',\n",
    "        r'online_or_offline_pin_required': 'online or offline pin required',\n",
    "        r'1000': 'approved',\n",
    "        r'1001': 'approved',\n",
    "        r'1002': 'approved',\n",
    "        r'1003': 'approved',\n",
    "        r'1004': 'approved',\n",
    "        r'2001': 'insufficient funds',\n",
    "        r'2002': 'limit exceeded',\n",
    "        r'2003': 'incorrect number',\n",
    "        r'2005': 'incorrect number',\n",
    "        r'2000': 'do not honor',\n",
    "        r'2044': 'declined call issuer',\n",
    "        r'2046': 'declined',\n",
    "        r'2013': 'stolen card',\n",
    "        r'2007': 'invalid account',\n",
    "        r'2004': 'expired card',\n",
    "        r'2047': 'pickup card',\n",
    "        r'2010': 'incorrect cvc',\n",
    "        r'2021': 'security violation',\n",
    "        r'2020': 'violation',\n",
    "        r'2057': 'card restriction',\n",
    "        r'3000': 'try again later',\n",
    "        r'2026': 'invalid merchant id',\n",
    "        r'2014': 'processor declined fraud suspected',\n",
    "        r'2019': 'invalid transaction',\n",
    "        r'2048': 'invalid amount',\n",
    "        r'2009': 'no such issuer',\n",
    "        r'2016': 'duplicate transaction',\n",
    "        r'2037': 'already reversed',\n",
    "        r'2017': 'cardholder stopped billing',\n",
    "        r'2018': 'cardholder stopped billing',\n",
    "        r'2056': 'transaction amount exceeded division amount',\n",
    "        r'2041': 'call issuer',\n",
    "        r'2038': 'processor declined',\n",
    "        r'2015': 'transaction not allowed',\n",
    "        r'2034': 'no action taken',\n",
    "        r'2043': 'do not try again',\n",
    "        r'2008': 'card account length error',\n",
    "        r'2022': 'updated cardholder available',\n",
    "        r'2006': 'invalid expiration date',\n",
    "        r'2053': 'lost or stolen',\n",
    "        r'2012': 'lost card',\n",
    "        r'2102': 'incorrect pin',\n",
    "        r'2103': 'pin try exceeded',\n",
    "        r'2105': 'cannot authorize at this time life cycle',\n",
    "        r'2106': 'cannot authorize at this time policy',\n",
    "        r'2107': 'card not activated',\n",
    "        r'.*Deny.*': 'declined',\n",
    "        r'.*Payment complete.*': 'Approved',\n",
    "        r'.*85 : No reason to decline a request for account number verification.*': 'Approved'\n",
    "    }\n",
    "\n",
    "    #Can do a Lamda function instead\n",
    "    # Use regular expressions to apply conditions and assign values to the new column based on the dictionary\n",
    "    for regex, value in regex_values_dict.items():\n",
    "        data.loc[data['decline_reason'].str.contains(regex, case=False, na=False, regex=True), 'decline_reason'] = value\n",
    "\n",
    "    # Loop over unique decline reasons\n",
    "    for reason in data['decline_reason'].unique():\n",
    "        # Check if the reason is not found in the values dictionary\n",
    "        if reason not in regex_values_dict.values():\n",
    "            # Assign 'other' to rows where the decline reason matches\n",
    "            data.loc[data['decline_reason'] == reason, 'decline_reason'] = 'other'\n",
    "    \n",
    "    \n",
    "    # Ensure the 'currency' column is of type string and convert to uppercase\n",
    "    data['currency'] = data['currency'].astype(str).str.upper()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"insufficent\" in data['decline_reason']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_validation(data, unique_columns):\n",
    " \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.expand_frame_repr', False)\n",
    "    \n",
    "    # Check for duplicate transaction IDs\n",
    "    duplicate_transactions = data.duplicated(subset= unique_columns).sum()\n",
    "    print(f\"Duplicate transaction by unique columns: {duplicate_transactions}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    status_counts = data['status'].value_counts(normalize=True)\n",
    "    approved_count = status_counts.get('Approved', 0)\n",
    "    declined_count = status_counts.get('Declined', 0)\n",
    "\n",
    "    # Check if the percentage of \"Approved\" or \"Declined\" is less than 10%\n",
    "    print( \"Check the percentage of 'Approved' or 'Declined' \")\n",
    "    if approved_count < 0.1:\n",
    "        print(\"######### Warning: Approved transactions are less than 10% of the total data.###############\")\n",
    "    if declined_count < 0.1:\n",
    "        print(\"######### Warning: Declined transactions are less than 10% of the total data.###############\")\n",
    "\n",
    "    print(data['status'].value_counts())\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Check for 'created' in column names and if it's a timestamp\n",
    "    print(\"Check timestamp if exists in the data:\")\n",
    "    try:\n",
    "        # Attempt to convert to datetime\n",
    "        data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "    except ValueError as e:\n",
    "        print(f\"Created at is now a possible time_stamp: {e}\")    \n",
    "    if pd.api.types.is_datetime64_any_dtype(data['created_at']):\n",
    "        min_date = data['created_at'].min()\n",
    "        max_date = data['created_at'].max()\n",
    "        print(\"created_at is a timestamp column.\")\n",
    "        print(\"Minimum date:\", min_date)\n",
    "        print(\"Maximum date:\", max_date)\n",
    "        print(\"Date difference (days):\", (max_date - min_date).days)\n",
    "    else:\n",
    "        print(\"No timestamp column containing 'created' found.\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"Checks for US currency:\")\n",
    "    currency_counts = data['currency'].value_counts(normalize=True) \n",
    "    usd_counts = currency_counts.get('USD', 0)\n",
    "    if usd_counts < 0.1:\n",
    "        print(\"Warning: Missing data from US\")\n",
    "    else:\n",
    "        print(\"US data is exist.\")\n",
    "    print(data['currency'].value_counts(normalize=True))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    # Check which currencies are missing in the exchange rate table\n",
    "    exchange_currencies = exchange_rate_table['currency'].unique()\n",
    "    data_currencies = data['currency'].unique()\n",
    "    missing_currencies = [currency for currency in data_currencies if currency not in exchange_currencies]\n",
    "    print(\"Missing Currencies from table:\")\n",
    "    print(missing_currencies)\n",
    "    \n",
    "    pd.reset_option('display.max_rows')\n",
    "    pd.reset_option('display.max_columns') \n",
    "    pd.reset_option('display.expand_frame_repr', False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GBP', 'INR', 'EUR', 'BRL', 'SEK', 'NOK', 'ILS', 'AUD', 'RUB',\n",
       "       'JPY', 'NZD', 'KRW', 'CAD', 'CNY', 'DKK', 'CHF'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_rate_table['currency'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Maybe you meant '==' or ':=' instead of '='? (2125126392.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    if order_by = 'status'\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Maybe you meant '==' or ':=' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "def feature_engineering(data, grouped_by, order_by, fixed_exchange_rates):\n",
    "    #Adding root transactions\n",
    "    if order_by = 'status'\n",
    "        status_priority = {'Declined': 1, 'Approved': 2}\n",
    "\n",
    "        # Apply custom sorting within each group and assign rank\n",
    "        data['retry_number'] = (\n",
    "            data.assign(status_priority=data['status'].map(status_priority))\n",
    "            .sort_values(by=grouped_by + ['status_priority', order_by])\n",
    "            .groupby(grouped_by)\n",
    "            .cumcount() + 1\n",
    "        )\n",
    "\n",
    "    # Drop the helper column used for sorting\n",
    "    data.drop(columns='status_priority', inplace=True)\n",
    "    else:\n",
    "        data['retry_number'] = data.groupby(grouped_by)[order_by].rank(method='first')\n",
    "    \n",
    "    # Adding  last retry decision \n",
    "    grouped_data = data.groupby(grouped_by)['status'].apply(lambda x: x.isin(['Success', 'Approved']).max()).reset_index(name='last_retry_decision')\n",
    "\n",
    "    # Merge the aggregated result back to the original DataFrame based on the grouping columns\n",
    "    data = data.merge(grouped_data, on=grouped_by, how='left')\n",
    "    \n",
    "    #last retry decline reason for renewals\n",
    "    # Determine the max retry number for each transaction_id\n",
    "    max_retry_per_transaction = data.groupby(grouped_by)['retry_number'].max().reset_index()\n",
    "\n",
    "    # Merge with original dataframe to get corresponding decline reason for max retry\n",
    "    merged_data = pd.merge(data, max_retry_per_transaction, on=grouped_by + ['retry_number'], how='inner')\n",
    "    # data['last_retry_decline_reason'] = merged_data['decline_reason']\n",
    "    # Create a dictionary mapping transaction_id to the corresponding decline_reason for the max retry number\n",
    "    transaction_id_to_decline_reason = dict(zip(merged_data['transaction_id'], merged_data['decline_reason']))\n",
    "\n",
    "    # Map the transaction_id in data to the corresponding decline_reason using the dictionary\n",
    "    data['last_retry_decline_reason'] = data['transaction_id'].map(transaction_id_to_decline_reason)\n",
    "    \n",
    "    # Add USD amount column\n",
    "    data = pd.merge(data, exchange_rate_table, how='left', left_on=['currency', 'created_at'], right_on=['currency', 'date'])\n",
    "\n",
    "\n",
    "    # # Define a function to calculate usd_amount\n",
    "    # def calculate_usd_amount(row):\n",
    "    #     if pd.notna(row['rate']):  # If exchange rate is available in the exchange rate table\n",
    "    #         exchange_rate = row['rate']\n",
    "    #     else:  # If exchange rate is not available, use fixed exchange rate\n",
    "    #         exchange_rate = fixed_exchange_rates.get(row['currency'], None)\n",
    "    #     if exchange_rate is None:\n",
    "    #         return None  # Handle cases where exchange rate is not available\n",
    "    #     return round(row['amount'] * exchange_rate, 1)\n",
    "\n",
    "    # # Apply the function to calculate usd_amount\n",
    "    # data['usd_amount'] = data.apply(calculate_usd_amount, axis=1)\n",
    "  \n",
    "\n",
    "    ###################################################Needs to check if this is correct instead of the function above\n",
    "    # Apply lambda function to calculate usd_amount\n",
    "    data['usd_amount'] = data.apply(\n",
    "        lambda row: round(row['amount'] * (row['rate'] if pd.notna(row['rate']) else fixed_exchange_rates.get(row['currency'], None)), 1) if fixed_exchange_rates.get(row['currency'], None) or pd.notna(row['rate']) else None,\n",
    "        axis=1\n",
    "    )\n",
    "    columns_to_remove = ['id', 'rate', 'date', 'created_at_y', 'updated_at']\n",
    "    data.drop(columns=columns_to_remove, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill the data with the instruction below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/mnt/c/Users/user/Desktop/bouncepay/Project/Analyist Dash/Book Away Payments Data.csv\")\n",
    "# data = pd.read_csv(\"/mnt/c/Users/user/Desktop/bouncepay/Project/Analyist Dash/march_acq_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Created date (UTC)</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Amount Refunded</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Captured</th>\n",
       "      <th>Converted Amount</th>\n",
       "      <th>Converted Amount Refunded</th>\n",
       "      <th>Converted Currency</th>\n",
       "      <th>Description</th>\n",
       "      <th>...</th>\n",
       "      <th>vehicleType (metadata)</th>\n",
       "      <th>type (metadata)</th>\n",
       "      <th>route (metadata)</th>\n",
       "      <th>operator (metadata)</th>\n",
       "      <th>departureTime (metadata)</th>\n",
       "      <th>bookingReference (metadata)</th>\n",
       "      <th>supplier (metadata)</th>\n",
       "      <th>country (metadata)</th>\n",
       "      <th>customerName (metadata)</th>\n",
       "      <th>countryOfResidence (metadata)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ch_3OvzUaDOj3CanVD00TkJyRW0</td>\n",
       "      <td>2024-03-19 10:02:00</td>\n",
       "      <td>39.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>True</td>\n",
       "      <td>39.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Standard bus-ferry</td>\n",
       "      <td>Departure Trip</td>\n",
       "      <td>Koh Phi Phi to Phuket</td>\n",
       "      <td>Phi Phi Cruiser</td>\n",
       "      <td>Wed, Mar 20th 2024 at 09:00</td>\n",
       "      <td>BW1997702</td>\n",
       "      <td>Phi Phi Cruiser</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Rick Van der Werf</td>\n",
       "      <td>Netherlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-03-19 10:01:00</td>\n",
       "      <td>25.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>VIP 9 Express bus</td>\n",
       "      <td>Departure Trip</td>\n",
       "      <td>Departure from Hoi An</td>\n",
       "      <td>Techbus VN JSC</td>\n",
       "      <td>Fri, Mar 22nd 2024 at 10:15</td>\n",
       "      <td>BW1997696</td>\n",
       "      <td>Travelier Connect</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Christian Weber</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ch_3OvzT6DOj3CanVD01C9Dnf4u</td>\n",
       "      <td>2024-03-19 10:00:00</td>\n",
       "      <td>138.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>True</td>\n",
       "      <td>138.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Comfort minivan</td>\n",
       "      <td>Departure Trip</td>\n",
       "      <td>Split to Tisno</td>\n",
       "      <td>MPM Transferi</td>\n",
       "      <td>Wed, Jul 10th 2024 at 15:00</td>\n",
       "      <td>BW1997699</td>\n",
       "      <td>MPM Transferi</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>Mia Bucciol</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ch_3OvzSBDOj3CanVD00JPnEoJg</td>\n",
       "      <td>2024-03-19 09:59:00</td>\n",
       "      <td>25.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>True</td>\n",
       "      <td>25.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Standard minivan</td>\n",
       "      <td>Departure Trip</td>\n",
       "      <td>Puerto Princesa to El Nido</td>\n",
       "      <td>Eulen Joy Express</td>\n",
       "      <td>Mon, Apr 1st 2024 at 09:30</td>\n",
       "      <td>BW1997698</td>\n",
       "      <td>Eulen Joy Express</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>Nicholas Gidley</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ch_3OvzSFDOj3CanVD02z3txlqs</td>\n",
       "      <td>2024-03-19 09:59:00</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>True</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>VIP 24 Seats bus</td>\n",
       "      <td>Departure Trip</td>\n",
       "      <td>Departure from Phuket</td>\n",
       "      <td>Minibus 1996</td>\n",
       "      <td>Sat, Mar 23rd 2024 at 10:40</td>\n",
       "      <td>BW1997695</td>\n",
       "      <td>Travelier Connect</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>Filipa Ribeiro</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id   Created date (UTC)  Amount  Amount Refunded  \\\n",
       "0  ch_3OvzUaDOj3CanVD00TkJyRW0  2024-03-19 10:02:00   39.52              0.0   \n",
       "1                          NaN  2024-03-19 10:01:00   25.61              NaN   \n",
       "2  ch_3OvzT6DOj3CanVD01C9Dnf4u  2024-03-19 10:00:00  138.35              0.0   \n",
       "3  ch_3OvzSBDOj3CanVD00JPnEoJg  2024-03-19 09:59:00   25.16              0.0   \n",
       "4  ch_3OvzSFDOj3CanVD02z3txlqs  2024-03-19 09:59:00   13.76              0.0   \n",
       "\n",
       "  Currency Captured  Converted Amount  Converted Amount Refunded  \\\n",
       "0      eur     True             39.52                        0.0   \n",
       "1      eur      NaN               NaN                        NaN   \n",
       "2      eur     True            138.35                        0.0   \n",
       "3      eur     True             25.16                        0.0   \n",
       "4      eur     True             13.76                        0.0   \n",
       "\n",
       "  Converted Currency                                        Description  ...  \\\n",
       "0                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "1                NaN  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "2                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "3                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "4                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "\n",
       "   vehicleType (metadata) type (metadata)            route (metadata)  \\\n",
       "0      Standard bus-ferry  Departure Trip       Koh Phi Phi to Phuket   \n",
       "1       VIP 9 Express bus  Departure Trip       Departure from Hoi An   \n",
       "2         Comfort minivan  Departure Trip              Split to Tisno   \n",
       "3        Standard minivan  Departure Trip  Puerto Princesa to El Nido   \n",
       "4        VIP 24 Seats bus  Departure Trip       Departure from Phuket   \n",
       "\n",
       "  operator (metadata)     departureTime (metadata)  \\\n",
       "0     Phi Phi Cruiser  Wed, Mar 20th 2024 at 09:00   \n",
       "1      Techbus VN JSC  Fri, Mar 22nd 2024 at 10:15   \n",
       "2       MPM Transferi  Wed, Jul 10th 2024 at 15:00   \n",
       "3   Eulen Joy Express   Mon, Apr 1st 2024 at 09:30   \n",
       "4        Minibus 1996  Sat, Mar 23rd 2024 at 10:40   \n",
       "\n",
       "  bookingReference (metadata) supplier (metadata) country (metadata)  \\\n",
       "0                   BW1997702     Phi Phi Cruiser           Thailand   \n",
       "1                   BW1997696   Travelier Connect            Vietnam   \n",
       "2                   BW1997699       MPM Transferi            Croatia   \n",
       "3                   BW1997698   Eulen Joy Express        Philippines   \n",
       "4                   BW1997695   Travelier Connect           Thailand   \n",
       "\n",
       "  customerName (metadata)  countryOfResidence (metadata)  \n",
       "0       Rick Van der Werf                    Netherlands  \n",
       "1         Christian Weber                        Germany  \n",
       "2             Mia Bucciol                      Australia  \n",
       "3         Nicholas Gidley                 United Kingdom  \n",
       "4          Filipa Ribeiro                       Portugal  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['invoice_date', 'transaction_id', 'user_id', 'payment_type',\n",
      "       'card_type', 'product', 'origin_country', 'region', 'attempt_status',\n",
      "       'funding_source', 'scheme', 'bin_number', 'gateway_message',\n",
      "       'gateway_code', 'processor_response_code', 'processor_response_text',\n",
      "       'status', 'issuing_bank', 'iso_currency_code', 'amount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"/mnt/c/Users/user/Desktop/bouncepay/Project/Analyist Dash/Book Away Payments Data.csv\")\n",
    "columns_mapping = {\n",
    "    'transaction_id': 'transaction_id',\n",
    "    'decline_reason': 'processor_response_text',\n",
    "    'created_at': 'invoice_date',\n",
    "    'amount': 'amount',\n",
    "    'currency': 'iso_currency_code',\n",
    "    'buyer_id': 'user_id',  # - Customer email/ subscription_id (For identifying self retries)\n",
    "    'retry': '', #If they have column fo retry \n",
    "    'status': 'status', # Success/Failed/Approved/Declined etc..\n",
    "    'type': '', # Transaction type checkout/renewal\n",
    "    'last_retry_decision': '', # - Decision of the last retry (Approve/Decline) will add after\n",
    "    'usd_amount': '', # - Will add after\n",
    "    'retry_number': '', # - Will add after\n",
    "    'last_retry_decline_reason': '' # if it's a renewal will add after\n",
    "}\n",
    "\n",
    "\n",
    "#Here write the columns needs to be unique with no duplicates\n",
    "unique_columns = ['transaction_id', 'created_at', 'amount']  # Enter column name who should be unique\n",
    "sort_data = []\n",
    "data_clean = clean_data(data, columns_mapping, unique_columns, sort_data) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate transaction by unique columns: 0\n",
      "\n",
      "\n",
      "Check the percentage of 'Approved' or 'Declined' \n",
      "status\n",
      "Approved     474403\n",
      "Declined     267987\n",
      "Cancelled       534\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "Check timestamp if exists in the data:\n",
      "created_at is a timestamp column.\n",
      "Minimum date: 2024-03-01 00:00:00\n",
      "Maximum date: 2024-03-31 00:00:00\n",
      "Date difference (days): 30\n",
      "\n",
      "\n",
      "Checks for US currency:\n",
      "US data is exist.\n",
      "currency\n",
      "USD    0.849422\n",
      "CAD    0.038443\n",
      "AUD    0.024023\n",
      "KRW    0.018112\n",
      "GBP    0.016630\n",
      "TRY    0.011495\n",
      "PHP    0.009230\n",
      "ZAR    0.008471\n",
      "HKD    0.005614\n",
      "SAR    0.005403\n",
      "MXN    0.004174\n",
      "SGD    0.002806\n",
      "AED    0.002380\n",
      "MYR    0.002240\n",
      "IDR    0.001470\n",
      "INR    0.000052\n",
      "EUR    0.000035\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "\n",
      "Missing Currencies from table:\n",
      "['USD', 'MYR', 'HKD', 'SAR', 'AED', 'IDR', 'PHP', 'TRY', 'SGD', 'ZAR', 'MXN']\n"
     ]
    }
   ],
   "source": [
    "data_validation(data_clean, unique_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to group by and order by in order to determine retry number\n",
    "grouped_by = ['user_id', 'created_at', 'amount'] \n",
    "\n",
    "order_by = 'status'\n",
    "fixed_exchange_rates = {\n",
    "    'USD': 1,\n",
    "    'BGN': 0.56,\n",
    "    'DKK': 0.15,\n",
    "    'NZD': 0.63,\n",
    "    'RSD': 0.0092,\n",
    "    'PLN': 0.25,\n",
    "    'BDT': 0.0094,\n",
    "    'SGD': 0.76,\n",
    "    'TRY': 0.034,\n",
    "    'KES': 0.0064,\n",
    "    'NOK': 0.098,\n",
    "    'ZAR': 0.055,\n",
    "    'PEN': 0.27,\n",
    "    'ISK': 0.0074,\n",
    "    'AMD': 0.0025,\n",
    "    'DZD': 0.0074,\n",
    "    'USD': 1,\n",
    "    'AUD': 0.68,\n",
    "    'HUF': 0.0029,\n",
    "    'DOP': 0.017,\n",
    "    'BRL': 0.21,\n",
    "    'MXN': 0.059,\n",
    "    'CHF': 1.19,\n",
    "    'UAH': 0.026,\n",
    "    'RUB': 0.011,\n",
    "    'AED': 0.27,\n",
    "    'CRC': 0.0019,\n",
    "    'THB': 0.029,\n",
    "    'EUR': 1.10,\n",
    "    'MYR': 0.22,\n",
    "    'COP': 0.00026,\n",
    "    'VND': 0.000041,\n",
    "    'GBP': 1.27,\n",
    "    'ARS': 0.0012,\n",
    "    'GEL': 0.37,\n",
    "    'PKR': 0.0036,\n",
    "    'SAR': 0.27,\n",
    "    'ILS': 0.28,\n",
    "    'INR': 0.012,\n",
    "    'HKD': 0.13,\n",
    "    'SEK': 0.099,\n",
    "    'JMD': 0.0065,\n",
    "    'PHP': 0.018,\n",
    "    'CLP': 0.0011,\n",
    "    'JPY': 0.0071,\n",
    "    'EGP': 0.032,\n",
    "    'KRW': 0.00077,\n",
    "    'RON': 0.22,\n",
    "    'TWD': 0.032,\n",
    "    'TND': 0.32,\n",
    "    'NGN': 0.0011,\n",
    "    'IDR': 0.000064,\n",
    "    'CAD': 0.76,\n",
    "    'PHP': 0.017\n",
    "    \n",
    "}\n",
    "fix_data =  feature_engineering(data_clean, grouped_by, order_by, fixed_exchange_rates)\n",
    "fix_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_data =  feature_engineering(data_clean, grouped_by, order_by, fixed_exchange_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>created_at_x</th>\n",
       "      <th>amount</th>\n",
       "      <th>Amount Refunded</th>\n",
       "      <th>currency</th>\n",
       "      <th>Captured</th>\n",
       "      <th>Converted Amount</th>\n",
       "      <th>Converted Amount Refunded</th>\n",
       "      <th>Converted Currency</th>\n",
       "      <th>Description</th>\n",
       "      <th>...</th>\n",
       "      <th>departureTime (metadata)</th>\n",
       "      <th>bookingReference (metadata)</th>\n",
       "      <th>supplier (metadata)</th>\n",
       "      <th>country (metadata)</th>\n",
       "      <th>customerName (metadata)</th>\n",
       "      <th>countryOfResidence (metadata)</th>\n",
       "      <th>retry_number</th>\n",
       "      <th>last_retry_decision</th>\n",
       "      <th>last_retry_decline_reason</th>\n",
       "      <th>usd_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ch_3OTX5UDOj3CanVD01I6nVi49</td>\n",
       "      <td>2023-12-31 22:03:00</td>\n",
       "      <td>51.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>True</td>\n",
       "      <td>51.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Sat, Jan 6th 2024 at 20:45</td>\n",
       "      <td>BW1650470</td>\n",
       "      <td>Clickbus Mexico API</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Caya van den Akker</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Approved</td>\n",
       "      <td>56.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ch_3OTX5UDOj3CanVD0272isoao</td>\n",
       "      <td>2023-12-31 22:03:00</td>\n",
       "      <td>46.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>True</td>\n",
       "      <td>46.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Tue, Jan 2nd 2024 at 11:30</td>\n",
       "      <td>BW1650472</td>\n",
       "      <td>The Panama Travel Tour</td>\n",
       "      <td>Panama</td>\n",
       "      <td>Stephanie Henne</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Approved</td>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ch_3OTX7BDOj3CanVD00fLZcNfB</td>\n",
       "      <td>2023-12-31 22:04:00</td>\n",
       "      <td>21.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>True</td>\n",
       "      <td>21.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Sat, Jan 6th 2024 at 12:20</td>\n",
       "      <td>BW1650473</td>\n",
       "      <td>Marlin Espadas</td>\n",
       "      <td>Belize</td>\n",
       "      <td>Erza Agolli</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Approved</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ch_3OTXBxDOj3CanVD00SYBBsqC</td>\n",
       "      <td>2023-12-31 22:09:00</td>\n",
       "      <td>52.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>True</td>\n",
       "      <td>52.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Mon, Jan 1st 2024 at 16:00</td>\n",
       "      <td>BW1650478</td>\n",
       "      <td>Clickbus Mexico API</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Steven Pillon</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>Approved</td>\n",
       "      <td>58.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ch_3OTXFlDOj3CanVD01HkqHFK6</td>\n",
       "      <td>2023-12-31 22:13:00</td>\n",
       "      <td>13.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>EUR</td>\n",
       "      <td>False</td>\n",
       "      <td>13.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eur</td>\n",
       "      <td>\\n    This is not your ticket.\\n    Remember t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Mon, Jan 1st 2024 at 16:00</td>\n",
       "      <td>BW1650481</td>\n",
       "      <td>Distribusion API</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>Jaspreet Singh</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>do not honor</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                transaction_id        created_at_x  amount  Amount Refunded  \\\n",
       "0  ch_3OTX5UDOj3CanVD01I6nVi49 2023-12-31 22:03:00   51.04              0.0   \n",
       "1  ch_3OTX5UDOj3CanVD0272isoao 2023-12-31 22:03:00   46.27              0.0   \n",
       "2  ch_3OTX7BDOj3CanVD00fLZcNfB 2023-12-31 22:04:00   21.47              0.0   \n",
       "3  ch_3OTXBxDOj3CanVD00SYBBsqC 2023-12-31 22:09:00   52.79              0.0   \n",
       "4  ch_3OTXFlDOj3CanVD01HkqHFK6 2023-12-31 22:13:00   13.43              0.0   \n",
       "\n",
       "  currency Captured  Converted Amount  Converted Amount Refunded  \\\n",
       "0      EUR     True             51.04                        0.0   \n",
       "1      EUR     True             46.27                        0.0   \n",
       "2      EUR     True             21.47                        0.0   \n",
       "3      EUR     True             52.79                        0.0   \n",
       "4      EUR    False             13.43                        0.0   \n",
       "\n",
       "  Converted Currency                                        Description  ...  \\\n",
       "0                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "1                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "2                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "3                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "4                eur  \\n    This is not your ticket.\\n    Remember t...  ...   \n",
       "\n",
       "     departureTime (metadata) bookingReference (metadata)  \\\n",
       "0  Sat, Jan 6th 2024 at 20:45                   BW1650470   \n",
       "1  Tue, Jan 2nd 2024 at 11:30                   BW1650472   \n",
       "2  Sat, Jan 6th 2024 at 12:20                   BW1650473   \n",
       "3  Mon, Jan 1st 2024 at 16:00                   BW1650478   \n",
       "4  Mon, Jan 1st 2024 at 16:00                   BW1650481   \n",
       "\n",
       "      supplier (metadata) country (metadata)  customerName (metadata)  \\\n",
       "0     Clickbus Mexico API             Mexico       Caya van den Akker   \n",
       "1  The Panama Travel Tour             Panama          Stephanie Henne   \n",
       "2          Marlin Espadas             Belize              Erza Agolli   \n",
       "3     Clickbus Mexico API             Mexico            Steven Pillon   \n",
       "4        Distribusion API           Portugal           Jaspreet Singh   \n",
       "\n",
       "  countryOfResidence (metadata) retry_number last_retry_decision  \\\n",
       "0                   Netherlands          1.0                True   \n",
       "1                       Germany          1.0                True   \n",
       "2                United Kingdom          1.0                True   \n",
       "3                     Australia          1.0                True   \n",
       "4                      Portugal          1.0               False   \n",
       "\n",
       "  last_retry_decline_reason  usd_amount  \n",
       "0                  Approved        56.1  \n",
       "1                  Approved        50.9  \n",
       "2                  Approved        23.6  \n",
       "3                  Approved        58.1  \n",
       "4              do not honor        14.8  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_data.head()\n",
    "# try_data.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
